{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting onnx==1.16.1 (from -r requirements-onnx-build.txt (line 1))\n",
      "  Using cached onnx-1.16.1-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime==1.19.2 (from -r requirements-onnx-build.txt (line 2))\n",
      "  Using cached onnxruntime-1.19.2-cp312-cp312-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: onnxruntime-genai==0.4.0 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements-onnx-build.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: protobuf==3.20.2 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements-onnx-build.txt (line 4)) (3.20.2)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements-onnx-build.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.0 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements-onnx-build.txt (line 6)) (2.2.0)\n",
      "Collecting transformers==4.41.2 (from -r requirements-onnx-build.txt (line 7))\n",
      "  Using cached transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (24.3.25)\n",
      "Requirement already satisfied: packaging in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (1.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.0->-r requirements-onnx-build.txt (line 6)) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.0->-r requirements-onnx-build.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.0->-r requirements-onnx-build.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.0->-r requirements-onnx-build.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.2.0->-r requirements-onnx-build.txt (line 6)) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (0.24.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7))\n",
      "  Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from coloredlogs->onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch==2.2.0->-r requirements-onnx-build.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers==4.41.2->-r requirements-onnx-build.txt (line 7)) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy->onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\tejasree\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime==1.19.2->-r requirements-onnx-build.txt (line 2)) (3.4.1)\n",
      "Using cached onnx-1.16.1-cp312-cp312-win_amd64.whl (14.4 MB)\n",
      "Using cached onnxruntime-1.19.2-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "Installing collected packages: onnx, tokenizers, onnxruntime, transformers\n",
      "  Attempting uninstall: onnxruntime\n",
      "    Found existing installation: onnxruntime 1.19.0\n",
      "    Uninstalling onnxruntime-1.19.0:\n",
      "      Successfully uninstalled onnxruntime-1.19.0\n",
      "Successfully installed onnx-1.16.1 onnxruntime-1.19.2 tokenizers-0.19.1 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements-onnx-build.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download phi-3-mini-4k model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Phi-3-mini-4k-instruct'...\n",
      "Filtering content:  66% (2/3), 2.48 GiB | 4.28 MiB/s\n",
      "Filtering content:  66% (2/3), 3.11 GiB | 4.03 MiB/s\n",
      "Filtering content: 100% (3/3), 3.11 GiB | 4.03 MiB/s\n",
      "Filtering content: 100% (3/3), 3.11 GiB | 4.02 MiB/s, done.\n",
      "Encountered 1 file(s) that may not have been copied correctly on Windows:\n",
      "\tmodel-00001-of-00002.safetensors\n",
      "\n",
      "See: `git lfs help smudge` for more details.\n"
     ]
    }
   ],
   "source": [
    "!cd hf-models && git clone https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd hf-models && git clone https://huggingface.co/microsoft/Phi-3-mini-128k-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ONNX version of phi-3-mini-4k model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid precision + execution provider combinations are: FP32 CPU, FP32 CUDA, FP16 CUDA, FP16 DML, INT4 CPU, INT4 CUDA, INT4 DML\n",
      "Extra options: {'int4_accuracy_level': '4'}\n",
      "GroupQueryAttention (GQA) is used in this model.\n",
      "Reading embedding layer\n",
      "Reading decoder layer 0\n",
      "Reading decoder layer 1\n",
      "Reading decoder layer 2\n",
      "Reading decoder layer 3\n",
      "Reading decoder layer 4\n",
      "Reading decoder layer 5\n",
      "Reading decoder layer 6\n",
      "Reading decoder layer 7\n",
      "Reading decoder layer 8\n",
      "Reading decoder layer 9\n",
      "Reading decoder layer 10\n",
      "Reading decoder layer 11\n",
      "Reading decoder layer 12\n",
      "Reading decoder layer 13\n",
      "Reading decoder layer 14\n",
      "Reading decoder layer 15\n",
      "Reading decoder layer 16\n",
      "Reading decoder layer 17\n",
      "Reading decoder layer 18\n",
      "Reading decoder layer 19\n",
      "Reading decoder layer 20\n",
      "Reading decoder layer 21\n",
      "Reading decoder layer 22\n",
      "Reading decoder layer 23\n",
      "Reading decoder layer 24\n",
      "Reading decoder layer 25\n",
      "Reading decoder layer 26\n",
      "Reading decoder layer 27\n",
      "Reading decoder layer 28\n",
      "Reading decoder layer 29\n",
      "Reading decoder layer 30\n",
      "Reading decoder layer 31\n",
      "Reading final norm\n",
      "Reading LM head\n",
      "Saving ONNX model in onnx-built-models\n",
      "Saving GenAI config in onnx-built-models\n",
      "Saving processing files in onnx-built-models for GenAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejasree\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tejasree\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2024-09-10 20:42:20,846 transformers_modules.Phi-3-mini-4k-instruct.modeling_phi3 [WARNING] - `flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "2024-09-10 20:42:20,846 transformers_modules.Phi-3-mini-4k-instruct.modeling_phi3 [WARNING] - Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.65s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 24.84s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.72s/it]\n",
      "2024-09-10 20:47:46,856 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:48,352 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:48,355 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:48,662 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:48,663 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:49,120 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:49,121 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:49,602 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:49,604 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.0/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:50,239 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.0/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:50,241 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:51,058 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:51,059 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:51,534 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:51,534 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:52,091 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:52,091 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:52,702 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:52,705 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.1/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:53,113 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.1/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:53,114 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:53,753 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:53,755 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:53,922 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:53,922 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:54,244 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:54,245 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:54,589 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:54,591 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.2/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:55,031 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.2/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:55,031 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:55,503 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:55,505 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:55,663 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:55,663 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:56,095 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:56,097 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:56,499 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:56,500 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.3/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:56,815 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.3/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:56,816 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:57,300 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:57,301 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:57,454 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:57,454 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:57,760 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:57,761 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:58,141 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:58,142 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.4/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:58,587 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.4/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:47:58,590 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:58,926 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:47:58,928 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:59,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:47:59,077 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:59,415 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:47:59,416 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:59,755 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:47:59,757 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.5/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:00,191 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.5/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:00,192 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:00,702 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:00,703 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:00,841 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:00,841 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:01,192 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:01,193 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:01,514 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:01,519 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.6/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:01,873 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.6/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:01,874 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:02,460 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:02,461 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:02,600 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:02,600 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:02,910 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:02,913 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:03,251 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:03,253 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.7/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:03,652 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.7/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:03,654 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:04,158 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:04,159 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:04,423 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:04,423 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:04,768 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:04,769 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:05,067 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:05,069 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.8/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:05,480 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.8/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:05,481 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:05,920 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:05,923 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:06,078 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:06,078 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:06,388 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:06,390 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:06,711 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:06,712 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.9/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:07,379 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.9/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:07,380 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:07,745 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:07,746 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:07,901 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:07,901 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:08,250 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:08,250 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:08,609 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:08,611 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.10/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:09,159 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.10/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:09,164 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:09,668 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:09,669 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:09,827 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:09,827 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:10,185 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:10,186 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:10,527 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:10,528 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.11/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:11,063 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.11/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:11,064 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:11,490 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:11,491 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:11,655 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:11,655 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:11,963 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:11,964 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:12,334 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:12,338 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.12/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:12,754 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.12/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:12,756 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:13,341 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:13,343 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:13,481 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:13,481 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:13,822 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:13,823 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:14,336 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:14,338 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.13/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:14,723 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.13/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:14,725 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:15,188 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:15,190 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:15,340 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:15,340 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:15,629 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:15,631 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:16,037 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:16,050 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.14/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:16,529 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.14/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:16,531 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:17,118 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:17,119 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:17,326 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:17,326 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:17,654 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:17,655 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:18,081 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:18,083 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.15/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:18,482 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.15/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:18,484 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:18,854 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:18,855 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:19,070 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:19,070 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:19,387 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:19,389 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:19,796 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:19,803 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.16/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:20,246 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.16/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:20,248 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:20,851 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:20,852 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:21,007 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:21,008 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:21,397 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:21,398 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:21,781 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:21,789 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.17/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:22,310 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.17/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:22,311 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:22,900 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:22,902 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:23,080 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:23,081 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:23,531 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:23,533 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:23,964 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:23,964 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.18/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:24,443 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.18/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:24,445 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:24,959 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:24,960 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:25,143 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:25,143 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:25,667 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:25,668 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:26,318 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:26,319 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.19/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:26,822 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.19/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:26,823 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:27,487 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:27,488 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:27,641 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:27,642 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:28,117 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:28,118 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:28,515 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:28,516 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.20/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:28,851 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.20/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:28,852 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:29,125 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:29,126 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:29,218 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:29,218 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:29,471 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:29,473 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:29,727 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:29,729 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.21/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:29,966 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.21/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:29,968 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:30,266 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:30,269 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:30,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:30,369 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:30,635 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:30,637 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:30,899 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:30,901 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.22/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:31,162 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.22/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:31,165 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:31,492 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:31,495 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:31,722 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:31,723 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:31,971 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:31,972 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:32,220 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:32,221 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.23/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:32,463 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.23/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:32,465 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:33,545 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:33,546 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:33,628 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:33,628 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:33,856 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:33,858 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:34,089 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:34,090 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.24/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:34,348 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.24/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:34,349 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:34,632 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:34,634 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:34,726 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:34,726 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:34,957 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:34,960 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:35,188 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:35,189 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.25/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:35,440 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.25/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:35,442 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:35,724 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:35,726 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:35,815 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:35,816 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:36,048 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:36,049 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:36,281 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:36,282 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.26/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:36,534 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.26/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:36,535 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:36,815 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:36,817 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:36,901 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:36,901 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:37,121 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:37,122 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:37,349 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:37,351 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.27/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:37,602 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.27/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:37,604 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:37,876 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:37,878 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:37,968 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:37,968 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:38,201 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:38,202 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:38,436 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:38,438 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.28/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:38,684 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.28/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:38,687 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:38,962 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:38,962 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:39,058 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:39,058 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:39,292 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:39,292 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:39,522 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:39,523 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.29/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:39,781 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.29/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:39,783 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:40,060 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:40,062 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:40,160 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:40,160 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:40,399 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:40,401 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:40,629 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:40,631 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.30/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:40,874 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.30/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:40,876 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:41,155 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/attn/qkv_proj/MatMul ...\n",
      "2024-09-10 20:48:41,157 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:41,248 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/attn/o_proj/MatMul ...\n",
      "2024-09-10 20:48:41,248 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:41,488 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/mlp/gate_proj/MatMul ...\n",
      "2024-09-10 20:48:41,489 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:41,719 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/mlp/up_proj/MatMul ...\n",
      "2024-09-10 20:48:41,720 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /model/layers.31/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:41,963 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /model/layers.31/mlp/down_proj/MatMul ...\n",
      "2024-09-10 20:48:41,964 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - start to quantize /lm_head/MatMul ...\n",
      "2024-09-10 20:48:42,888 onnxruntime.quantization.matmul_4bits_quantizer [INFO] - complete quantization of /lm_head/MatMul ...\n",
      "C:\\Users\\tejasree\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:848: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tejasree\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime_genai.models.builder -m hf-models/Phi-3-mini-4k-instruct -o onnx-built-models -p int4 -e cpu --extra_options int4_block_size=32 --extra_options int4_accuracy_level=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
